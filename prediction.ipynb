{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27c690ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8573c745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SALARY PREDICTION MODEL - DETAILED ANALYSIS\n",
      "============================================================\n",
      "Analysis started at: 2025-07-21 04:47:33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SALARY PREDICTION MODEL - DETAILED ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f995d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: LOADING DATASET\n",
      "------------------------------\n",
      "Dataset shape: (375, 6)\n",
      "Columns: ['Age', 'Gender', 'Education Level', 'Job Title', 'Years of Experience', 'Salary']\n",
      "\n",
      "First 5 rows:\n",
      "    Age  Gender Education Level          Job Title  Years of Experience  \\\n",
      "0  32.0    Male      Bachelor's  Software Engineer                  5.0   \n",
      "1  28.0  Female        Master's       Data Analyst                  3.0   \n",
      "2  45.0    Male             PhD     Senior Manager                 15.0   \n",
      "3  36.0  Female      Bachelor's    Sales Associate                  7.0   \n",
      "4  52.0    Male        Master's           Director                 20.0   \n",
      "\n",
      "     Salary  \n",
      "0   90000.0  \n",
      "1   65000.0  \n",
      "2  150000.0  \n",
      "3   60000.0  \n",
      "4  200000.0  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375 entries, 0 to 374\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Age                  373 non-null    float64\n",
      " 1   Gender               373 non-null    object \n",
      " 2   Education Level      373 non-null    object \n",
      " 3   Job Title            373 non-null    object \n",
      " 4   Years of Experience  373 non-null    float64\n",
      " 5   Salary               373 non-null    float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 17.7+ KB\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load dataset\n",
    "print(\"STEP 1: LOADING DATASET\")\n",
    "print(\"-\" * 30)\n",
    "df = pd.read_csv(\"Data/Salary Data.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head(5))\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a77ece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: DATA QUALITY ANALYSIS\n",
      "-----------------------------------\n",
      "Missing values per column:\n",
      "Age                    2\n",
      "Gender                 2\n",
      "Education Level        2\n",
      "Job Title              2\n",
      "Years of Experience    2\n",
      "Salary                 2\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 12\n",
      "\n",
      "Data types:\n",
      "Age                    float64\n",
      "Gender                  object\n",
      "Education Level         object\n",
      "Job Title               object\n",
      "Years of Experience    float64\n",
      "Salary                 float64\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Quality Check\n",
    "print(\"STEP 2: DATA QUALITY ANALYSIS\")\n",
    "print(\"-\" * 35)\n",
    "print(\"Missing values per column:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "print(f\"\\nTotal missing values: {missing_values.sum()}\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49edbc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: DESCRIPTIVE STATISTICS\n",
      "-----------------------------------\n",
      "Numerical columns statistics:\n",
      "              Age  Years of Experience         Salary\n",
      "count  373.000000           373.000000     373.000000\n",
      "mean    37.431635            10.030831  100577.345845\n",
      "std      7.069073             6.557007   48240.013482\n",
      "min     23.000000             0.000000     350.000000\n",
      "25%     31.000000             4.000000   55000.000000\n",
      "50%     36.000000             9.000000   95000.000000\n",
      "75%     44.000000            15.000000  140000.000000\n",
      "max     53.000000            25.000000  250000.000000\n",
      "\n",
      "Categorical columns value counts:\n",
      "\n",
      "Gender:\n",
      "Gender\n",
      "Male      194\n",
      "Female    179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Education Level:\n",
      "Education Level\n",
      "Bachelor's    224\n",
      "Master's       98\n",
      "PhD            51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Job Title:\n",
      "Job Title\n",
      "Director of Marketing              12\n",
      "Director of Operations             11\n",
      "Senior Business Analyst            10\n",
      "Senior Marketing Analyst            9\n",
      "Senior Marketing Manager            9\n",
      "                                   ..\n",
      "Business Development Manager        1\n",
      "Customer Service Representative     1\n",
      "IT Manager                          1\n",
      "Digital Marketing Manager           1\n",
      "Junior Web Developer                1\n",
      "Name: count, Length: 174, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Basic Statistics\n",
    "print(\"STEP 3: DESCRIPTIVE STATISTICS\")\n",
    "print(\"-\" * 35)\n",
    "print(\"Numerical columns statistics:\")\n",
    "print(df.describe())\n",
    "print()\n",
    "\n",
    "print(\"Categorical columns value counts:\")\n",
    "categorical_columns = [\"Gender\", \"Education Level\", \"Job Title\"]\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df[col].value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb0528f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: SALARY DISTRIBUTION ANALYSIS\n",
      "----------------------------------------\n",
      "Salary statistics:\n",
      "Mean: $100,577.35\n",
      "Median: $95,000.00\n",
      "Standard Deviation: $48,240.01\n",
      "Min: $350.00\n",
      "Max: $250,000.00\n",
      "25th percentile: $55,000.00\n",
      "75th percentile: $140,000.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Salary Analysis\n",
    "print(\"STEP 4: SALARY DISTRIBUTION ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "if 'Salary' in df.columns:\n",
    "    print(f\"Salary statistics:\")\n",
    "    print(f\"Mean: ${df['Salary'].mean():,.2f}\")\n",
    "    print(f\"Median: ${df['Salary'].median():,.2f}\")\n",
    "    print(f\"Standard Deviation: ${df['Salary'].std():,.2f}\")\n",
    "    print(f\"Min: ${df['Salary'].min():,.2f}\")\n",
    "    print(f\"Max: ${df['Salary'].max():,.2f}\")\n",
    "    print(f\"25th percentile: ${df['Salary'].quantile(0.25):,.2f}\")\n",
    "    print(f\"75th percentile: ${df['Salary'].quantile(0.75):,.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29563894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: DATA CLEANING\n",
      "-------------------------\n",
      "Rows before cleaning: 375\n",
      "Rows with missing salary: 2\n",
      "Rows after cleaning: 373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Data Cleaning\n",
    "print(\"STEP 5: DATA CLEANING\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"Rows before cleaning: {len(df)}\")\n",
    "print(f\"Rows with missing salary: {df['Salary'].isnull().sum()}\")\n",
    "\n",
    "# Dropping rows where Salary is missing\n",
    "df.dropna(subset=[\"Salary\"], inplace=True)\n",
    "print(f\"Rows after cleaning: {len(df)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69826a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 6: FEATURE PREPARATION\n",
      "--------------------------------\n",
      "Features shape: (373, 5)\n",
      "Target shape: (373,)\n",
      "Features: ['Age', 'Gender', 'Education Level', 'Job Title', 'Years of Experience']\n",
      "Categorical columns: ['Gender', 'Education Level', 'Job Title']\n",
      "Numerical columns: ['Age', 'Years of Experience']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Feature Engineering\n",
    "print(\"STEP 6: FEATURE PREPARATION\")\n",
    "print(\"-\" * 32)\n",
    "# Features and target\n",
    "X = df.drop(\"Salary\", axis=1)\n",
    "y = df[\"Salary\"]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "\n",
    "# Column identification\n",
    "categorical_cols = [\"Gender\", \"Education Level\", \"Job Title\"]\n",
    "numerical_cols = [\"Age\", \"Years of Experience\"]\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95eed0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 7: PREPROCESSING PIPELINE\n",
      "-----------------------------------\n",
      "Preprocessing pipeline created:\n",
      "- Numerical: Median imputation\n",
      "- Categorical: Most frequent imputation + One-hot encoding\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Preprocessing Pipeline Setup\n",
    "print(\"STEP 7: PREPROCESSING PIPELINE\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "categorical_preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_preprocessor, numerical_cols),\n",
    "    ('cat', categorical_preprocessor, categorical_cols)\n",
    "])\n",
    "\n",
    "print(\"Preprocessing pipeline created:\")\n",
    "print(\"- Numerical: Median imputation\")\n",
    "print(\"- Categorical: Most frequent imputation + One-hot encoding\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a97876e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 8: MODEL PIPELINE CREATION\n",
      "-----------------------------------\n",
      "Random Forest Regressor pipeline created with parameters:\n",
      "- n_estimators: 100\n",
      "- max_depth: 10\n",
      "- min_samples_split: 5\n",
      "- min_samples_leaf: 2\n",
      "- random_state: 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Model Pipeline\n",
    "print(\"STEP 8: MODEL PIPELINE CREATION\")\n",
    "print(\"-\" * 35)\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2\n",
    "    ))\n",
    "])\n",
    "print(\"Random Forest Regressor pipeline created with parameters:\")\n",
    "print(\"- n_estimators: 100\")\n",
    "print(\"- max_depth: 10\")\n",
    "print(\"- min_samples_split: 5\")\n",
    "print(\"- min_samples_leaf: 2\")\n",
    "print(\"- random_state: 42\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca4d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 9: TRAIN-TEST SPLIT\n",
      "------------------------------\n",
      "Training set size: 298 samples\n",
      "Test set size: 75 samples\n",
      "Train ratio: 79.9%\n",
      "Test ratio: 20.1%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Train-Test Split\n",
    "print(\"STEP 9: TRAIN-TEST SPLIT\")\n",
    "print(\"-\" * 30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Train ratio: {X_train.shape[0]/len(df)*100:.1f}%\")\n",
    "print(f\"Test ratio: {X_test.shape[0]/len(df)*100:.1f}%\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2ac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 10: MODEL TRAINING\n",
      "-------------------------\n",
      "Training the model...\n",
      "Model training completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Model Training\n",
    "print(\"STEP 10: MODEL TRAINING\")\n",
    "print(\"-\" * 25)\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd2419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 11: MODEL EVALUATION\n",
      "------------------------------\n",
      "TRAINING SET PERFORMANCE:\n",
      "RMSE: $9,942.02\n",
      "MAE: $6,566.33\n",
      "R² Score: 0.9570\n",
      "\n",
      "TEST SET PERFORMANCE:\n",
      "RMSE: $17,080.61\n",
      "MAE: $10,436.18\n",
      "R² Score: 0.8783\n",
      "\n",
      "Overfitting Check:\n",
      "RMSE difference (train vs test): $7,138.58\n",
      "R² difference (train vs test): 0.0787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Model Evaluation\n",
    "print(\"STEP 11: MODEL EVALUATION\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Training predictions\n",
    "train_preds = model.predict(X_train)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "train_mae = mean_absolute_error(y_train, train_preds)\n",
    "\n",
    "# Test predictions\n",
    "test_preds = model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "test_mae = mean_absolute_error(y_test, test_preds)\n",
    "\n",
    "print(\"TRAINING SET PERFORMANCE:\")\n",
    "print(f\"RMSE: ${train_rmse:,.2f}\")\n",
    "print(f\"MAE: ${train_mae:,.2f}\")\n",
    "print(f\"R² Score: {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nTEST SET PERFORMANCE:\")\n",
    "print(f\"RMSE: ${test_rmse:,.2f}\")\n",
    "print(f\"MAE: ${test_mae:,.2f}\")\n",
    "print(f\"R² Score: {test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nOverfitting Check:\")\n",
    "print(f\"RMSE difference (train vs test): ${abs(train_rmse - test_rmse):,.2f}\")\n",
    "print(f\"R² difference (train vs test): {abs(train_r2 - test_r2):.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6159e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 12: FEATURE IMPORTANCE ANALYSIS\n",
      "----------------------------------------\n",
      "Top 10 Most Important Features:\n",
      "Age                           : 0.6098\n",
      "Years of Experience           : 0.3370\n",
      "Education Level_Bachelor's    : 0.0250\n",
      "Education Level_PhD           : 0.0046\n",
      "Education Level_Master's      : 0.0040\n",
      "Job Title_Administrative Assistant: 0.0031\n",
      "Gender_Female                 : 0.0031\n",
      "Gender_Male                   : 0.0028\n",
      "Job Title_Senior Project Manager: 0.0022\n",
      "Job Title_Recruiter           : 0.0014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Feature Importance\n",
    "print(\"STEP 12: FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "feature_names = (numerical_cols +\n",
    "                 list(model.named_steps['preprocessor']\n",
    "                      .named_transformers_['cat']\n",
    "                      .named_steps['encoder']\n",
    "                      .get_feature_names_out(categorical_cols)))\n",
    "\n",
    "# Get feature importance\n",
    "importance_scores = model.named_steps['regressor'].feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importance_scores\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"{row['feature']:<30}: {row['importance']:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0cfde60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 13: PREDICTION EXAMPLES\n",
      "--------------------------------\n",
      "Sample predictions on test set:\n",
      "\n",
      "Sample 1:\n",
      "  Actual Salary: $35,000.00\n",
      "  Predicted Salary: $41,832.16\n",
      "  Absolute Error: $6,832.16\n",
      "  Error Percentage: 19.5%\n",
      "\n",
      "Sample 2:\n",
      "  Actual Salary: $50,000.00\n",
      "  Predicted Salary: $50,683.88\n",
      "  Absolute Error: $683.88\n",
      "  Error Percentage: 1.4%\n",
      "\n",
      "Sample 3:\n",
      "  Actual Salary: $160,000.00\n",
      "  Predicted Salary: $143,317.35\n",
      "  Absolute Error: $16,682.65\n",
      "  Error Percentage: 10.4%\n",
      "\n",
      "Sample 4:\n",
      "  Actual Salary: $90,000.00\n",
      "  Predicted Salary: $89,959.44\n",
      "  Absolute Error: $40.56\n",
      "  Error Percentage: 0.0%\n",
      "\n",
      "Sample 5:\n",
      "  Actual Salary: $160,000.00\n",
      "  Predicted Salary: $156,938.42\n",
      "  Absolute Error: $3,061.58\n",
      "  Error Percentage: 1.9%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 13: Prediction Examples\n",
    "print(\"STEP 13: PREDICTION EXAMPLES\")\n",
    "print(\"-\" * 32)\n",
    "print(\"Sample predictions on test set:\")\n",
    "sample_indices = np.random.choice(len(X_test), 5, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    actual = y_test.iloc[idx]\n",
    "    predicted = test_preds[idx]\n",
    "    error = abs(actual - predicted)\n",
    "    error_pct = (error / actual) * 100\n",
    "\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Actual Salary: ${actual:,.2f}\")\n",
    "    print(f\"  Predicted Salary: ${predicted:,.2f}\")\n",
    "    print(f\"  Absolute Error: ${error:,.2f}\")\n",
    "    print(f\"  Error Percentage: {error_pct:.1f}%\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbff4ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 14: MODEL SAVING\n",
      "-------------------------\n",
      "Model saved as: salary_predictor_model_enhanced.joblib\n",
      "Feature importance saved as: feature_importance.csv\n",
      "Model metrics saved as: model_metrics.csv\n",
      "\n",
      "============================================================\n",
      "MODEL ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Analysis completed at: 2025-07-21 04:50:45\n",
      "\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "Dataset: 373 samples, 6 features\n",
      "Model Type: Random Forest Regressor\n",
      "Test R² Score: 0.8783\n",
      "Test RMSE: $17,080.61\n",
      "Model saved successfully!\n",
      "Ready for Streamlit app deployment!\n"
     ]
    }
   ],
   "source": [
    "# Step 14: Model Persistence\n",
    "print(\"STEP 14: MODEL SAVING\")\n",
    "print(\"-\" * 25)\n",
    "model_filename = \"salary_predictor_model_enhanced.joblib\"\n",
    "joblib.dump(model, model_filename)\n",
    "print(f\"Model saved as: {model_filename}\")\n",
    "\n",
    "# Save feature importance for later use\n",
    "feature_importance.to_csv(\"feature_importance.csv\", index=False)\n",
    "print(\"Feature importance saved as: feature_importance.csv\")\n",
    "\n",
    "# Save model metrics\n",
    "metrics = {\n",
    "    'train_rmse': train_rmse,\n",
    "    'test_rmse': test_rmse,\n",
    "    'train_r2': train_r2,\n",
    "    'test_r2': test_r2,\n",
    "    'train_mae': train_mae,\n",
    "    'test_mae': test_mae\n",
    "}\n",
    "pd.Series(metrics).to_csv(\"model_metrics.csv\")\n",
    "print(\"Model metrics saved as: model_metrics.csv\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: {len(df)} samples, {len(df.columns)} features\")\n",
    "print(f\"Model Type: Random Forest Regressor\")\n",
    "print(f\"Test R² Score: {test_r2:.4f}\")\n",
    "print(f\"Test RMSE: ${test_rmse:,.2f}\")\n",
    "print(f\"Model saved successfully!\")\n",
    "print(\"Ready for Streamlit app deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
